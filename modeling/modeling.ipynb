{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'..\\preprocessing\\tidy_data.csv', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Số dòng và cột của dữ liệu\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Các thuộc tính của dữ liệu\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tính khoảng thời gian điện thoại đã ra mắt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['time'] = pd.to_datetime(data['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính toán khoảng thời gian hiện tại - 'time'\n",
    "data['time_difference'] = datetime.now() - data['time']\n",
    "data['time_difference'] = data['time_difference'].dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['time'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tính thời gian hết bảo hành"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_results = []\n",
    "current_date = datetime.now() # Lấy ngày và giờ hiện tại\n",
    "\n",
    "for index, item in data['warranty'].items():\n",
    "    item = str(item).strip() # Đảm bảo item là chuỗi và loại bỏ khoảng trắng\n",
    "\n",
    "    # Kiểm tra nếu có chứa \"tháng\"\n",
    "    if \"tháng\" in item:\n",
    "        num_months_str = item.replace(\"tháng\", \"\").strip()\n",
    "        num_months = int(num_months_str)\n",
    "\n",
    "        # Xử lý cộng tháng\n",
    "        year = current_date.year\n",
    "        month = current_date.month + num_months\n",
    "        day = current_date.day\n",
    "\n",
    "        while month > 12:\n",
    "            month -= 12\n",
    "            year += 1\n",
    "                \n",
    "        # Xử lý trường hợp ngày không hợp lệ sau khi cộng tháng\n",
    "        try:\n",
    "            new_date = datetime(year, month, day)\n",
    "        except ValueError:\n",
    "            # Nếu ngày không hợp lệ, lấy ngày cuối cùng của tháng đó\n",
    "            last_day_of_month = calendar.monthrange(year, month)[1]\n",
    "            new_date = datetime(year, month, last_day_of_month)\n",
    "\n",
    "        # Cập nhật giá trị\n",
    "        data.loc[index, 'warranty'] = new_date.strftime(\"%d/%m/%Y\")\n",
    "    else:\n",
    "            datetime.strptime(item, \"%d/%m/%Y\")\n",
    "            data.loc[index, 'warranty'] = item \n",
    "\n",
    "# Chuyển dữ liệu sang kiểu datetime\n",
    "data['warranty'] = pd.to_datetime(data['warranty'], format='%d/%m/%Y', errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo một Series mới cho current_date\n",
    "current_date_series = pd.Series([current_date] * len(data))\n",
    "\n",
    "# Tính hiệu số ngày\n",
    "time_remaining = data['warranty'] - current_date_series\n",
    "\n",
    "# Lưu vào một cột mới\n",
    "data['day_remaining_warranty'] = time_remaining.dt.days + 1\n",
    "data['day_remaining_warranty'] = data['day_remaining_warranty'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['warranty'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chọn thuộc tính"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kiểm tra các thuộc tính object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "def calculate_entropy(data):\n",
    "    entropy_values = {}\n",
    "    for column in data.columns:\n",
    "        probabilities = data[column].dropna().value_counts(normalize=True)\n",
    "        entropy_values[column] = entropy(probabilities, base=2)\n",
    "    return entropy_values\n",
    "\n",
    "# Tính entropy cho từng thuộc tính\n",
    "entropy_results = calculate_entropy(data[categorical_columns])\n",
    "print(entropy_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- image có entropy cao nhất (13.42), cho thấy mỗi giá trị gần như là duy nhất, không hữu ích cho mô hình. \n",
    "- Các biến như name, CPU, GPU có entropy cao (trên 4), phản ánh sự đa dạng lớn. \n",
    "- brand, display_technology, color có entropy trung bình (khoảng 2.7–3.9), cân bằng giữa thông tin và độ phức tạp. \n",
    "- condition, bluetooth, operating_system có entropy thấp (dưới 2.5), cho thấy ít giá trị phân loại, ít khả năng phân biệt hơn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "def cramers_v(x, y):\n",
    "    confusion_matrix = pd.crosstab(x, y)\n",
    "    chi2 = stats.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum().sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    return np.sqrt(phi2 / min(r-1, k-1))\n",
    "\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Tính Cramér's V giữa từng thuộc tính object và price_old\n",
    "cramer_results = {col: cramers_v(data[col], data['price_old']) for col in categorical_columns}\n",
    "print(cramer_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Các biến như brand, CPU, GPU, OS có Cramér’s V cao (trên 0.75), nghĩa là liên hệ rất mạnh với biến mục tiêu.\n",
    "- Biến color có giá trị thấp nhất (≈ 0.65), cho thấy liên hệ yếu nhất trong nhóm.\n",
    "- Biến image có Cramér’s V = 1.0 vì mỗi sản phẩm sẽ có link hình ảnh khác nhau -> không hữu ích trong phân tích."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Hàm kiểm định Kruskal-Wallis cho tất cả các biến phân loại với price_old\n",
    "def kruskal_test(df, target):\n",
    "    results = {}\n",
    "    for col in categorical_columns:\n",
    "        groups = [df[df[col] == cat][target] for cat in df[col].unique()]\n",
    "        if len(groups) > 1:  \n",
    "            kruskal_result = stats.kruskal(*groups)\n",
    "            results[col] = {'Statistic': kruskal_result.statistic, 'p-value': kruskal_result.pvalue}\n",
    "    return results\n",
    "\n",
    "# Thực hiện kiểm định\n",
    "kruskal_results = kruskal_test(data, 'price_old')\n",
    "print(kruskal_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Biến image có p-value khá cao (0.498). Điều này có nghĩa là image không có mối liên hệ thống kê đáng kể với price_old.   \n",
    "Biến color được loại bỏ vì tuy có ý nghĩa thống kê (p-value ≈ 0.0), nhưng mức độ liên hệ thực tế với biến mục tiêu lại yếu trong các biến (Cramér’s V ≈ 0.65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns = ['image', 'color'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kiểm tra các thuộc tính số"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "numeric_data = data.select_dtypes(include=np.number).drop('price_old', axis=1)\n",
    "\n",
    "correlation_matrix = numeric_data.corr(method='pearson')\n",
    "plt.figure(figsize=(15, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title(\"Ma trận tương quan giữa các thuộc tính số\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ngưỡng tương quan\n",
    "correlation_threshold = 0.8\n",
    "\n",
    "# Lọc các cặp có độ tương quan cao\n",
    "corr_series = correlation_matrix.unstack()\n",
    "high_corr_pairs = corr_series[\n",
    "    (corr_series.abs() > correlation_threshold) &\n",
    "    (corr_series.abs() < 1.0)\n",
    "]\n",
    "\n",
    "high_corr_pairs = high_corr_pairs.sort_values(ascending=False, key=abs)\n",
    "print(f\"Các cặp thuộc tính có độ tương quan tuyệt đối > {correlation_threshold}:\")\n",
    "printed_pairs = set()\n",
    "for (col1, col2), corr_value in high_corr_pairs.items():\n",
    "    pair = tuple(sorted((col1, col2)))\n",
    "    if pair not in printed_pairs:\n",
    "        print(f\"  - Cặp: {col1} - {col2}, Tương quan: {corr_value:.3f}\")\n",
    "        printed_pairs.add(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "# Tính VIF cho từng thuộc tính\n",
    "X = add_constant(numeric_data)\n",
    "\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = X.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif_data = vif_data[vif_data['feature'] != 'const']\n",
    "\n",
    "print(\"Kết quả VIF cho các thuộc tính số:\")\n",
    "print(vif_data.sort_values(by='VIF', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop những thuộc tính VIF lớn 10 (đa cộng tuyến nghiêm trọng) và có tương quan tuyệt đối > 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns = ['has_nano_sim', 'battery', 'screen_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau khi được loại bỏ các thuộc tính còn lại có độ tương quan giảm đáng kể."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển đổi đơn vị của price old và price new từ đồng sang ngàn đồng\n",
    "data['price_old'] = data['price_old']/1000\n",
    "data['price_new'] = data['price_new']/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chuyển đổi đơn vị từ pixel sang MP (megapixel)\n",
    "data['screen_resolution'] = data['screen_resolution']/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Lấy danh sách các cột số, ngoại trừ price_old\n",
    "numerical_cols = data.select_dtypes(include=['number']).columns.tolist()\n",
    "numerical_cols.remove(\"price_old\")  # Loại bỏ target khỏi danh sách\n",
    "\n",
    "# Xác định số hàng phù hợp\n",
    "num_plots = len(numerical_cols)\n",
    "ncols = 4  # Số cột cố định\n",
    "nrows = (num_plots // ncols) + (1 if num_plots % ncols != 0 else 0)  # Điều chỉnh số hàng\n",
    "\n",
    "# Vẽ biểu đồ scatter\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(15, nrows * 4))\n",
    "axes = axes.flatten()[:num_plots]  # Chỉ lấy đủ số subplot cần thiết\n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    axes[i].scatter(data[col], data[\"price_old\"], alpha=0.5)\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel(\"price_old\")\n",
    "    axes[i].set_title(f\"Tương quan giữa {col} và price_old\")\n",
    "\n",
    "# Ẩn các subplot thừa (nếu có)\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatterplot của day_remaining_warranty cho thấy nhiều điểm dữ liệu nhiễu, xu hướng ảnh hưởng đến price_old là không rõ ràng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['day_remaining_warranty'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xử lí operating system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phân loại theo mức độ cập nhật hệ điều hành."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_update_score(os_name):\n",
    "    if os_name.startswith(\"iOS\"):\n",
    "        match = re.search(r\"iOS\\s*(\\d+)\", os_name)\n",
    "        if match:\n",
    "            version = int(match.group(1))\n",
    "            return version / 18\n",
    "        return np.nan\n",
    "    elif os_name.startswith(\"Android\"):\n",
    "        match = re.search(r\"Android\\s*(\\d+)\", os_name)\n",
    "        if match:\n",
    "            version = int(match.group(1))\n",
    "            return version / 15\n",
    "        return np.nan\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "# Tính điểm cập nhật\n",
    "data['update_score'] = data['operating_system'].apply(get_update_score)\n",
    "\n",
    "# Gán NaN bằng giá trị trung bình\n",
    "mean_score = data['update_score'].mean()\n",
    "data['update_score'].fillna(mean_score, inplace=True)\n",
    "\n",
    "# Gán lại vào cột operating_system\n",
    "data['operating_system'] = data['update_score']\n",
    "\n",
    "# Xoá cột phụ\n",
    "data.drop(columns=['update_score'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xử lí CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gom nhóm CPU dựa trên hiệu năng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High performance\n",
    "high = data['CPU'].str.contains(\n",
    "    r'(?i)(?:a18|a17|a16|a15(?:\\sbionic)?|snapdragon\\s8(?:\\sgen\\s3|\\sgen\\s2|\\+?\\sgen\\s1)|8\\selite|exynos\\s2400(?:e)?|exynos\\s2200|dimensity\\s(?:9300\\+|9400|9200|8300))',\n",
    "    na=False\n",
    ")\n",
    "# Mid performance\n",
    "mid = data['CPU'].str.contains(\n",
    "    r'(?i)(?:a14(?:\\sbionic)?|a13(?:\\sbionic)?|snapdragon\\s(?:7(?:\\sgen\\s[13]|s\\sgen\\s2)|6\\sgen\\s[134]|6s\\s(?:gen\\s1|4g\\sgen\\s1))|exynos\\s(?:2100|15[80]|14[80]|13[80]|1280)|dimensity\\s(?:1080|7050|7025|7300|6300|6100\\+|6020|700|8350|d6300))',\n",
    "    na=False\n",
    ")\n",
    "# Low performance\n",
    "low = data['CPU'].str.contains(\n",
    "    r'(?i)(?:snapdragon\\s(?:6[895]|680(?:\\s4g)?|sm6225)|helio\\s(?:g(?:99|96|92|91|88|85|81|36|35)|p35|g100)|mt6762|unisoc\\s(?:t(?:7250|7225|615|612|606|107)|ums9117)|tiger\\s?t693)',\n",
    "    na=False\n",
    ")\n",
    "# Đặt mặc định cho các giá trị không khớp hoặc bị thiếu\n",
    "# Định nghĩa cấp độ CPU và nhãn tương ứng của chúng\n",
    "conditions = [high, mid, low]\n",
    "choices = ['3', '2', '1']  # 3: High, 2: Mid, 1: Low\n",
    "\n",
    "data['CPU'] = np.select(conditions, choices, default='1').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xử lí display technology"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phân loại thành 3 công nghệ chính"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LCD\n",
    "LCD = data['display_technology'].str.lower().str.contains(\n",
    "    'lcd|tn|liquid', na=False)\n",
    "# OLED\n",
    "OLED = data['display_technology'].str.lower().str.contains(\n",
    "    'oled|amoled|super retina xdr', na=False)\n",
    "# Unknown\n",
    "no_display_technology = data['display_technology'].isna() | (data['display_technology'].str.lower() == 'unknown')\n",
    "# Gán nhãn tương ứng\n",
    "conditions = [no_display_technology, LCD, OLED]\n",
    "choices = ['1', '2', '3']\n",
    "\n",
    "data['display_technology'] = np.select(conditions, choices, default='1')\n",
    "data['display_technology'] = pd.to_numeric(data['display_technology'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xử lí condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gán nhãn thủ công cho tình trạng của máy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Định nghĩa các tình trạng và nhãn số tương ứng của chúng\n",
    "condition_mapping = {\n",
    "    'Cũ trầy xước cấn': 1,\n",
    "    'Cũ trầy xước': 2,\n",
    "    'Cũ': 3,\n",
    "    'Cũ đẹp': 4,\n",
    "}\n",
    "\n",
    "# Ánh xạ mô tả thành các nhãn\n",
    "data['condition'] = data['condition'].map(condition_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xử lí brand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gắn nhãn thủ công cho nhãn dựa trên mức độ phổ biến và phân khúc thị trường của thương hiệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data['brand'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Định nghĩa thương hiệu và nhãn số tương ứng của chúng\n",
    "brand_mapping = {\n",
    "    'apple': 4,\n",
    "    'samsung': 4,\n",
    "\n",
    "    'honor': 3,\n",
    "    'oppo': 3,\n",
    "    'xiaomi': 3,\n",
    "    'vivo': 3,\n",
    "    \n",
    "    'realme': 2,\n",
    "    'tecno': 2,\n",
    "    'nokia': 2,\n",
    "    'tcl': 2,\n",
    "\n",
    "    'mobell': 1,\n",
    "    'viettel': 1,\n",
    "    'masstel': 1\n",
    "}\n",
    "\n",
    "# Ánh xạ nhãn cho cột 'brand'\n",
    "data['brand'] = data['brand'].map(brand_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xử lí name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dùng LabelEncoder để encode cho name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "name_encoder = LabelEncoder()\n",
    "data['name'] = name_encoder.fit_transform(data['name'])\n",
    "joblib.dump(name_encoder, 'name_label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xử lí GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dựa vào hiệu năng để gắn nhãn cho các dòng GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# High level \n",
    "high_cond = data['GPU'].str.lower().str.contains(\n",
    "    'adreno-7|adreno-8|mali-g7|mali-g76|mali-g77|mali-g78|apple-gpu 6|apple-gpu 5|immortalis|xclipse|powervr-series7xt', na=False)\n",
    "# Low level\n",
    "low_cond = data['GPU'].str.lower().str.contains(\n",
    "    'adreno-6|adreno-5|adreno-4|mali-g6|mali-g57|mali-g68|mali-g52|powervr-ge8320|xclipse-920|apple-gpu 4|adreno-619|adreno-644|adreno-670', na=False)\n",
    "# Unknown GPU\n",
    "no_gpu_cond = data['GPU'].isna() | (data['GPU'].str.lower() == 'unknown')\n",
    "\n",
    "# Gán nhãn tương ứng\n",
    "conditions = [no_gpu_cond, high_cond, low_cond]\n",
    "choices = ['1', '3', '2']\n",
    "\n",
    "data['GPU'] = np.select(conditions, choices, default='1')\n",
    "data['GPU'] = pd.to_numeric(data['GPU'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Xử lí bluetooth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dựa vào phiên bản và các tính năng để gắn trọng số"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bảng điểm version\n",
    "version_score_map = {\n",
    "    '2.1': 1.0,\n",
    "    '4.2': 2.0,\n",
    "    '5.0': 3.0,\n",
    "    '5.1': 3.2,\n",
    "    '5.2': 3.4,\n",
    "    '5.3': 3.6,\n",
    "    '5.4': 3.8,\n",
    "    '6.0': 4.0\n",
    "}\n",
    "\n",
    "# Trọng số profile\n",
    "profile_points = {\n",
    "    'apt-X Adaptive': 0.2,\n",
    "    'apt-X HD': 0.15,\n",
    "    'LHDC': 0.15,\n",
    "    'apt-X': 0.1,\n",
    "    'A2DP': 0.1,\n",
    "    'LE': 0.1,\n",
    "    'BLE': 0.05\n",
    "}\n",
    "\n",
    "# Hàm mã hóa\n",
    "def encode_bluetooth_weighted(bluetooth_str):\n",
    "    if pd.isna(bluetooth_str):\n",
    "        return np.nan\n",
    "\n",
    "    # Tìm version\n",
    "    version_match = re.findall(r'v(\\d\\.\\d)', bluetooth_str)\n",
    "    version = version_score_map.get(version_match[0], 0) if version_match else 0\n",
    "\n",
    "    # Tính điểm profile\n",
    "    profile_score = sum(pt for profile, pt in profile_points.items() if profile in bluetooth_str)\n",
    "\n",
    "    return round(version + profile_score, 2)\n",
    "\n",
    "# Áp dụng vào cột\n",
    "data['bluetooth'] = data['bluetooth'].apply(encode_bluetooth_weighted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Gom cụm dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "# Khởi tạo mô hình K-Means với k cụm\n",
    "k = 3\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "\n",
    "X = data.drop(columns=['price_old'])\n",
    "# Huấn luyện mô hình\n",
    "kmeans.fit(np.array(X))\n",
    "joblib.dump(kmeans, 'kmeans_model.pkl')\n",
    "\n",
    "# Nhận nhãn cụm và tâm cụm\n",
    "labels = kmeans.labels_\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "print(\"Nhóm:\", labels)\n",
    "print(\"Tâm cụm:\", centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clustered = pd.DataFrame(data)\n",
    "data_clustered[\"Cluster\"] = labels\n",
    "\n",
    "# Hiển thị danh sách price_old theo từng cụm\n",
    "print(data_clustered.groupby(\"Cluster\")[\"price_old\"].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Lấy danh sách các cột số (ngoại trừ price_old)\n",
    "numerical_cols = data_clustered.select_dtypes(include=['number']).columns.tolist()\n",
    "numerical_cols.remove(\"price_old\")  # Loại bỏ target khỏi danh sách\n",
    "\n",
    "# Vẽ tất cả các biểu đồ scatter\n",
    "fig, axes = plt.subplots(nrows=5, ncols=4, figsize=(15, len(numerical_cols)))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    axes[i].scatter(data_clustered[col], data[\"price_old\"], alpha=0.5)\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel(\"price_old\")\n",
    "    axes[i].set_title(f\"Tương quan giữa {col} và price_old\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clustered.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clustered = data_clustered.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clustered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chia tập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và tập dev + test theo tỷ lệ 60:40\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(data_clustered.drop(columns=['price_old']), data_clustered[\"price_old\"], test_size=0.4, random_state=42)\n",
    "\n",
    "# Chia tiếp tập dev + test thành tập dev (20%) và tập test (20%)\n",
    "X_dev, X_test, y_dev, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lưu các dữ liệu sau chia tập"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([X_train, y_train], axis=1)\n",
    "train_data.to_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = pd.concat([X_dev, y_dev], axis=1)\n",
    "dev_data.to_csv(\"dev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.concat([X_test, y_test], axis=1)\n",
    "test_data.to_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Huấn luyện mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': randint(3, 10),\n",
    "    'learning_rate': uniform(0.01, 0.2),\n",
    "    'subsample': uniform(0.7, 0.3),\n",
    "    'colsample_bytree': uniform(0.7, 0.3)\n",
    "}\n",
    "\n",
    "xgb = RandomizedSearchCV(\n",
    "    estimator=XGBRegressor(objective='reg:squarederror', random_state=42),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "print(\"Các siêu tham số tối ưu: \", xgb.best_params_)\n",
    "print(\"MSE tốt nhất:\", -xgb.best_score_)\n",
    "print(\"RMSE tốt nhất:\", np.sqrt(-xgb.best_score_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_regressor = xgb.best_estimator_\n",
    "\n",
    "# Huấn luyện mô hình trên tập train\n",
    "xgb_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán trên tập dev\n",
    "y_pred_xgb = xgb_regressor.predict(X_dev)\n",
    "\n",
    "# Đánh giá mô hình bằng MSE và RMSE trên tập dev\n",
    "mse_dev = mean_squared_error(y_dev, y_pred_xgb)\n",
    "rmse_dev = np.sqrt(mse_dev)\n",
    "mape = mean_absolute_percentage_error(y_dev, y_pred_xgb)\n",
    "r2 = r2_score(y_dev, y_pred_xgb)\n",
    "\n",
    "print(f\"MSE trên tập dev: {mse_dev}\")\n",
    "print(f\"RMSE trên tập dev: {rmse_dev}\")\n",
    "print(f\"MAPE trên tập dev: {mape}\")\n",
    "print(f\"R² trên tập dev: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBMRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# Tìm số lượng cây tối ưu cho mô hình bởi Early Stopping\n",
    "lgbm = LGBMRegressor(\n",
    "    objective='regression',\n",
    "    n_estimators=5000,\n",
    "    learning_rate=0.1,\n",
    "    num_leaves=31,\n",
    "    max_depth=20,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "lgbm.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_metric='rmse',\n",
    "    callbacks=[lgb.early_stopping(\n",
    "        stopping_rounds=50,\n",
    "        verbose=False\n",
    "    )],\n",
    ")\n",
    "\n",
    "# Số lượng cây tối ưu được chọn bởi Early Stopping\n",
    "n = lgbm.best_iteration_\n",
    "print(f\"\\nSố lượng cây tối ưu (n_estimators) được chọn bởi Early Stopping: {lgbm.best_iteration_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Định nghĩa không gian tham số (param_grid)\n",
    "param_grid = {\n",
    "    'n_estimators': [n],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'num_leaves': [20, 31, 40],\n",
    "    'max_depth': [-1, 10, 20],\n",
    "}\n",
    "\n",
    "lgbm = GridSearchCV(\n",
    "    estimator=LGBMRegressor(random_state=42),\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "lgbm.fit(X_train, y_train)\n",
    "\n",
    "# Lấy kết quả tốt nhất\n",
    "print(\"Tham số tốt nhất:\", lgbm.best_params_)\n",
    "print(\"MSE tốt nhất:\", -lgbm.best_score_)\n",
    "print(\"RMSE tốt nhất:\", np.sqrt(-lgbm.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo mô hình với các tham số được tinh chỉnh\n",
    "lgbm_regressor = lgbm.best_estimator_\n",
    "\n",
    "# Huấn luyện\n",
    "lgbm_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Dự đoán\n",
    "y_pred_lgbm = lgbm_regressor.predict(X_dev)\n",
    "\n",
    "# Đánh giá mô hình bằng MSE và RMSE trên tập dev\n",
    "mse_dev = mean_squared_error(y_dev, y_pred_lgbm)\n",
    "rmse_dev = np.sqrt(mse_dev)\n",
    "mape = mean_absolute_percentage_error(y_dev, y_pred_lgbm)\n",
    "r2 = r2_score(y_dev, y_pred_lgbm)\n",
    "\n",
    "print(f\"MSE trên tập dev: {mse_dev}\")\n",
    "print(f\"RMSE trên tập dev: {rmse_dev}\")\n",
    "print(f\"MAPE trên tập dev: {mape}\")\n",
    "print(f\"R² trên tập dev: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Thiết lập grid search với các giá trị siêu tham số cần thử nghiệm\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],  # Số lượng cây trong rừng\n",
    "    \"max_depth\": [None, 10, 20],      # Độ sâu tối đa của cây\n",
    "    \"min_samples_split\": [2, 5, 10],  # Số mẫu tối thiểu để chia nút\n",
    "    \"min_samples_leaf\": [1, 2, 4],    # Số mẫu tối thiểu ở nút lá\n",
    "    \"max_features\": [\"sqrt\", \"log2\"]  # Số lượng đặc trưng được chọn ngẫu nhiên\n",
    "}\n",
    "\n",
    "# Grid Search với cross-validation 5-fold\n",
    "rf= GridSearchCV(RandomForestRegressor(random_state=42),\n",
    "                param_grid = param_grid,\n",
    "                cv=5,\n",
    "                scoring=\"neg_root_mean_squared_error\",\n",
    "                n_jobs=-1,\n",
    "                verbose=2)\n",
    "\n",
    "# Huấn luyện\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Kết quả tốt nhất\n",
    "print(\"Tham số tốt nhất:\", rf.best_params_)\n",
    "print(\"MSE tốt nhất:\", -rf.best_score_)\n",
    "print(\"RMSE tốt nhất:\", np.sqrt(-rf.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_regressor = rf.best_estimator_\n",
    "\n",
    "# Dự đoán\n",
    "y_pred_rf = rf_regressor.predict(X_dev)\n",
    "\n",
    "# Đánh giá mô hình bằng MSE và RMSE trên tập dev\n",
    "mse_dev = mean_squared_error(y_dev, y_pred_rf)\n",
    "rmse_dev = np.sqrt(mse_dev)\n",
    "mape = mean_absolute_percentage_error(y_dev, y_pred_rf)\n",
    "r2 = r2_score(y_dev, y_pred_rf)\n",
    "\n",
    "print(f\"MSE trên tập dev: {mse_dev}\")\n",
    "print(f\"RMSE trên tập dev: {rmse_dev}\")\n",
    "print(f\"MAPE trên tập dev: {mape}\")\n",
    "print(f\"R² trên tập dev: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Định nghĩa không gian tham số\n",
    "param_dist = {\n",
    "    'iterations': randint(100, 1000),\n",
    "    'learning_rate': uniform(loc=0.01, scale=0.15),\n",
    "    'depth': randint(4, 10),\n",
    "    'l2_leaf_reg': uniform(loc=1, scale=5),\n",
    "}\n",
    "\n",
    "# Khởi tạo mô hình CatBoostRegressor\n",
    "cat_model_base = CatBoostRegressor(\n",
    "    random_state=42,\n",
    "    loss_function='RMSE',\n",
    "    eval_metric='R2',\n",
    "    early_stopping_rounds=50,\n",
    "    verbose=0,\n",
    ")\n",
    "\n",
    "# Khởi tạo RandomizedSearchCV\n",
    "random_search_catboost = RandomizedSearchCV(estimator=cat_model_base,\n",
    "                                            param_distributions=param_dist,\n",
    "                                            n_iter=30,\n",
    "                                            cv=5,\n",
    "                                            scoring='r2',\n",
    "                                            verbose=1,\n",
    "                                            random_state=42,\n",
    "                                            n_jobs=-1)\n",
    "\n",
    "# Huấn luyện mô hình CatBoost với RandomizedSearchCV\n",
    "random_search_catboost.fit(X_train, y_train,\n",
    "                           eval_set=(X_dev, y_dev),\n",
    "                           early_stopping_rounds=50,\n",
    "                           verbose=100\n",
    "                           )\n",
    "\n",
    "# Kết quả tốt nhất\n",
    "print(\"Tham số tốt nhất:\", random_search_catboost.best_params_)\n",
    "print(\"MSE tốt nhất:\", random_search_catboost.best_score_)\n",
    "print(\"RMSE tốt nhất:\", np.sqrt(random_search_catboost.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy mô hình CatBoost tốt nhất đã được huấn luyện\n",
    "cb_regressor = random_search_catboost.best_estimator_\n",
    "\n",
    "# Dự đoán trên tập dev\n",
    "y_pred_cb = cb_regressor.predict(X_dev)\n",
    "\n",
    "# Đánh giá mô hình bằng MSE và RMSE trên tập dev\n",
    "mse_dev = mean_squared_error(y_dev, y_pred_cb)\n",
    "rmse_dev = np.sqrt(mse_dev)\n",
    "mape = mean_absolute_percentage_error(y_dev, y_pred_cb)\n",
    "r2 = r2_score(y_dev, y_pred_cb)\n",
    "\n",
    "print(f\"MSE trên tập dev: {mse_dev}\")\n",
    "print(f\"RMSE trên tập dev: {rmse_dev}\")\n",
    "print(f\"MAPE trên tập dev: {mape}\")\n",
    "print(f\"R² trên tập dev: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kiểm định"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán\n",
    "y_pred_xgb = xgb_regressor.predict(X_test)\n",
    "\n",
    "# Đánh giá mô hình bằng MSE và RMSE trên tập test\n",
    "mse_test = mean_squared_error(y_test, y_pred_xgb)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred_xgb)\n",
    "r2 = r2_score(y_test, y_pred_xgb)\n",
    "\n",
    "print(f\"MSE trên tập test: {mse_test}\")\n",
    "print(f\"RMSE trên tập test: {rmse_test}\")\n",
    "print(f\"MAPE trên tập test: {mape}\")\n",
    "print(f\"R² trên tập test: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred_xgb, alpha=0.5, color='blue')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', label=\"Perfect prediction\")\n",
    "plt.xlabel(\"Thực tế\")\n",
    "plt.ylabel(\"Dự đoán\")\n",
    "plt.title(\"XGBRegressor\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Hiển thị biểu đồ\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán\n",
    "y_pred_lgbm = lgbm_regressor.predict(X_test)\n",
    "\n",
    "# Đánh giá mô hình bằng MSE và RMSE trên tập test\n",
    "mse_test = mean_squared_error(y_test, y_pred_lgbm)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred_lgbm)\n",
    "r2 = r2_score(y_test, y_pred_lgbm)\n",
    "\n",
    "print(f\"MSE trên tập test: {mse_test}\")\n",
    "print(f\"RMSE trên tập test: {rmse_test}\")\n",
    "print(f\"MAPE trên tập test: {mape}\")\n",
    "print(f\"R² trên tập test: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred_lgbm, alpha=0.5, color='blue')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', label=\"Perfect prediction\")\n",
    "plt.xlabel(\"Thực tế\")\n",
    "plt.ylabel(\"Dự đoán\")\n",
    "plt.title(\"LGBMRegressor\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Hiển thị biểu đồ\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán\n",
    "y_pred_rf = rf_regressor.predict(X_test)\n",
    "\n",
    "# Đánh giá mô hình bằng MSE và RMSE trên tập test\n",
    "mse_test = mean_squared_error(y_test, y_pred_rf)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred_rf)\n",
    "r2 = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "print(f\"MSE trên tập test: {mse_test}\")\n",
    "print(f\"RMSE trên tập test: {rmse_test}\")\n",
    "print(f\"MAPE trên tập test: {mape}\")\n",
    "print(f\"R² trên tập test: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred_rf, alpha=0.5, color='blue')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', label=\"Perfect prediction\")\n",
    "plt.xlabel(\"Thực tế\")\n",
    "plt.ylabel(\"Dự đoán\")\n",
    "plt.title(\"RandomForestRegressor\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Hiển thị biểu đồ\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán\n",
    "y_pred_cb = cb_regressor.predict(X_test)\n",
    "\n",
    "# Đánh giá mô hình bằng MSE và RMSE trên tập test\n",
    "mse_test = mean_squared_error(y_test, y_pred_cb)\n",
    "rmse_test = np.sqrt(mse_test)\n",
    "mape = mean_absolute_percentage_error(y_test, y_pred_cb)\n",
    "r2 = r2_score(y_test, y_pred_cb)\n",
    "\n",
    "print(f\"MSE trên tập test: {mse_test}\")\n",
    "print(f\"RMSE trên tập test: {rmse_test}\")\n",
    "print(f\"MAPE trên tập test: {mape}\")\n",
    "print(f\"R² trên tập test: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred_cb, alpha=0.5, color='blue')\n",
    "plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', label=\"Perfect prediction\")\n",
    "plt.xlabel(\"Thực tế\")\n",
    "plt.ylabel(\"Dự đoán\")\n",
    "plt.title(\"CatBoostRegressor\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Hiển thị biểu đồ\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lưu mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(xgb_regressor, 'xgb_model.pkl')\n",
    "joblib.dump(lgbm_regressor, 'lgbm_model.pkl')\n",
    "joblib.dump(rf_regressor, 'rf_model.pkl')\n",
    "joblib.dump(cb_regressor, 'cb_model.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lưu pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "import joblib\n",
    "\n",
    "X_original = pd.read_csv(r'..\\preprocessing\\tidy_data.csv', encoding='utf-8-sig').drop(columns=['price_old'])\n",
    "\n",
    "class Dropper(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.drop(columns=self.columns, errors='ignore').copy()\n",
    "\n",
    "class DateTimeFeaturesTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        X_copy['time'] = pd.to_datetime(X_copy['time'], errors='coerce')\n",
    "        X_copy['time_difference'] = (datetime.now() - X_copy['time']).dt.days\n",
    "\n",
    "        current_date_for_warranty = datetime.now()\n",
    "        warranty_processed_list = []\n",
    "\n",
    "        for item in X_copy['warranty']:\n",
    "            if pd.isna(item):\n",
    "                warranty_processed_list.append(np.nan)\n",
    "                continue\n",
    "            item_str = str(item).strip()\n",
    "            if \"tháng\" in item_str:\n",
    "                num_months_str = item_str.replace(\"tháng\", \"\").strip()\n",
    "                try:\n",
    "                    num_months = int(num_months_str)\n",
    "                except ValueError:\n",
    "                    warranty_processed_list.append(np.nan)\n",
    "                    continue\n",
    "                year = current_date_for_warranty.year\n",
    "                month = current_date_for_warranty.month + num_months\n",
    "                day = current_date_for_warranty.day\n",
    "                while month > 12:\n",
    "                    month -= 12\n",
    "                    year += 1\n",
    "                try:\n",
    "                    new_date = datetime(year, month, day)\n",
    "                except ValueError:\n",
    "                    last_day_of_month = calendar.monthrange(year, month)[1]\n",
    "                    new_date = datetime(year, month, last_day_of_month)\n",
    "                warranty_processed_list.append(new_date)\n",
    "            else:\n",
    "                try:\n",
    "                    warranty_processed_list.append(datetime.strptime(item_str, \"%d/%m/%Y\"))\n",
    "                except ValueError:\n",
    "                    warranty_processed_list.append(np.nan)\n",
    "\n",
    "        X_copy['warranty_processed'] = warranty_processed_list\n",
    "        current_date_series = pd.Series([current_date_for_warranty] * len(X_copy), index=X_copy.index)\n",
    "        time_remaining = X_copy['warranty_processed'] - current_date_series\n",
    "        X_copy['day_remaining_warranty'] = time_remaining.dt.days + 1\n",
    "\n",
    "        return X_copy.copy()\n",
    "\n",
    "class OperatingSystemTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.mean_score = None\n",
    "\n",
    "    def get_update_score(self, os_name):\n",
    "        if pd.isnull(os_name):\n",
    "            return np.nan\n",
    "        if os_name.startswith(\"iOS\"):\n",
    "            match = re.search(r\"iOS\\s*(\\d+)\", os_name)\n",
    "            if match:\n",
    "                version = int(match.group(1))\n",
    "                return version / 18\n",
    "        elif os_name.startswith(\"Android\"):\n",
    "            match = re.search(r\"Android\\s*(\\d+)\", os_name)\n",
    "            if match:\n",
    "                version = int(match.group(1))\n",
    "                return version / 15\n",
    "        return np.nan\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        scores = X['operating_system'].apply(self.get_update_score)\n",
    "        self.mean_score = scores.mean()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        X_copy['operating_system'] = X_copy['operating_system'].apply(self.get_update_score)\n",
    "        X_copy['operating_system'].fillna(self.mean_score, inplace=True)\n",
    "        return X_copy\n",
    "\n",
    "class CPUTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "\n",
    "        high_pattern = re.compile(\n",
    "            r'(?i)(?:a18|a17|a16|a15(?:\\sbionic)?|snapdragon\\s8(?:\\sgen\\s3|\\sgen\\s2|\\+?\\sgen\\s1)|8\\selite|'\n",
    "            r'exynos\\s2400(?:e)?|exynos\\s2200|dimensity\\s(?:9300\\+|9400|9200|8300))'\n",
    "        )\n",
    "        mid_pattern = re.compile(\n",
    "            r'(?i)(?:a14(?:\\sbionic)?|a13(?:\\sbionic)?|snapdragon\\s(?:7(?:\\sgen\\s[13]|s\\sgen\\s2)|'\n",
    "            r'6\\sgen\\s[134]|6s\\s(?:gen\\s1|4g\\sgen\\s1))|exynos\\s(?:2100|15[80]|14[80]|13[80]|1280)|'\n",
    "            r'dimensity\\s(?:1080|7050|7025|7300|6300|6100\\+|6020|700|8350|d6300))'\n",
    "        )\n",
    "        low_pattern = re.compile(\n",
    "            r'(?i)(?:snapdragon\\s(?:6[895]|680(?:\\s4g)?|sm6225)|helio\\s(?:g(?:99|96|92|91|88|85|81|36|35)|'\n",
    "            r'p35|g100)|mt6762|unisoc\\s(?:t(?:7250|7225|615|612|606|107)|ums9117)|tiger\\s?t693)'\n",
    "        )\n",
    "\n",
    "        def classify_cpu(cpu):\n",
    "            if pd.isnull(cpu):\n",
    "                return 1\n",
    "            cpu = cpu.strip()\n",
    "            if high_pattern.search(cpu):\n",
    "                return 3\n",
    "            elif mid_pattern.search(cpu):\n",
    "                return 2\n",
    "            elif low_pattern.search(cpu):\n",
    "                return 1\n",
    "            else:\n",
    "                return 1\n",
    "\n",
    "        X_copy['CPU'] = X_copy['CPU'].apply(classify_cpu).astype(int)\n",
    "        return X_copy\n",
    "\n",
    "class ConditionTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        condition_mapping = {'Cũ trầy xước cấn': 1, 'Cũ trầy xước': 2, 'Cũ': 3, 'Cũ đẹp': 4}\n",
    "        X_copy['condition'] = X_copy['condition'].map(condition_mapping).fillna(np.nan)\n",
    "        return X_copy.copy()\n",
    "\n",
    "class BrandTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        brand_mapping = {\n",
    "            'apple': 4, 'samsung': 4,\n",
    "            'honor': 3, 'oppo': 3, 'xiaomi': 3, 'vivo': 3,\n",
    "            'realme': 2, 'tecno': 2, 'nokia': 2, 'tcl': 2,\n",
    "            'mobell': 1, 'viettel': 1, 'masstel': 1\n",
    "        }\n",
    "        X_copy['brand'] = X_copy['brand'].str.lower().map(brand_mapping).fillna(np.nan)\n",
    "        return X_copy.copy()\n",
    "\n",
    "class NameEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, encoder):\n",
    "        self.encoder = encoder\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        mapping = {label: idx for idx, label in enumerate(self.encoder.classes_)}\n",
    "        X_copy['name'] = X_copy['name'].map(mapping).fillna(-1).astype(int)\n",
    "        return X_copy.copy()\n",
    "\n",
    "class GPUTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        high_cond = X_copy['GPU'].str.lower().str.contains(\n",
    "            'adreno-7|adreno-8|mali-g7|mali-g76|mali-g77|mali-g78|apple-gpu 6|apple-gpu 5|immortalis|xclipse|powervr-series7xt', na=False)\n",
    "        low_cond = X_copy['GPU'].str.lower().str.contains(\n",
    "            'adreno-6|adreno-5|adreno-4|mali-g6|mali-g57|mali-g68|mali-g52|powervr-ge8320|xclipse-920|apple-gpu 4|adreno-619|adreno-644|adreno-670', na=False)\n",
    "        no_gpu_cond = X_copy['GPU'].isna() | (X_copy['GPU'].str.lower() == 'unknown')\n",
    "        conditions = [no_gpu_cond, high_cond, low_cond]\n",
    "        choices = ['1', '3', '2']\n",
    "        X_copy['GPU'] = np.select(conditions, choices, default='1')\n",
    "        X_copy['GPU'] = pd.to_numeric(X_copy['GPU'], errors='coerce')\n",
    "        return X_copy.copy()\n",
    "\n",
    "class BluetoothTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        version_score_map = {\n",
    "            '2.1': 1.0, '4.2': 2.0, '5.0': 3.0, '5.1': 3.2, '5.2': 3.4, '5.3': 3.6, '5.4': 3.8, '6.0': 4.0\n",
    "        }\n",
    "        profile_points = {\n",
    "            'apt-X Adaptive': 0.2, 'apt-X HD': 0.15, 'LHDC': 0.15, 'apt-X': 0.1, 'A2DP': 0.1, 'LE': 0.1, 'BLE': 0.05\n",
    "        }\n",
    "        def encode_bluetooth_weighted(bluetooth_str):\n",
    "            if pd.isna(bluetooth_str):\n",
    "                return np.nan\n",
    "            version_match = re.findall(r'v(\\d\\.\\d)', bluetooth_str)\n",
    "            version = version_score_map.get(version_match[0], 0) if version_match else 0\n",
    "            profile_score = sum(pt for profile, pt in profile_points.items() if profile in bluetooth_str)\n",
    "            return round(version + profile_score, 2)\n",
    "        X_copy['bluetooth'] = X_copy['bluetooth'].apply(encode_bluetooth_weighted)\n",
    "        return X_copy.copy()\n",
    "\n",
    "class PriceNewTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        if 'price_new' in X_copy.columns:\n",
    "            X_copy['price_new'] = X_copy['price_new'].fillna(0) / 1000\n",
    "        return X_copy.copy()\n",
    "\n",
    "class ScreenResolutionTrasformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        if 'screen_resolution' in X_copy.columns:\n",
    "            X_copy['screen_resolution'] = pd.to_numeric(X_copy['screen_resolution'], errors='coerce')\n",
    "            X_copy['screen_resolution'] = X_copy['screen_resolution'].fillna(0) / 1000000\n",
    "        return X_copy.copy()\n",
    "\n",
    "class DisplayTechnologyTransformer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "\n",
    "        LCD = X_copy['display_technology'].str.lower().str.contains(\n",
    "            'lcd|tn|liquid', na=False)\n",
    "\n",
    "        OLED = X_copy['display_technology'].str.lower().str.contains(\n",
    "            'oled|amoled|super retina xdr', na=False)\n",
    "\n",
    "        no_display_technology = X_copy['display_technology'].isna() | (X_copy['display_technology'].str.lower() == 'unknown')\n",
    "\n",
    "        conditions = [no_display_technology, LCD, OLED]\n",
    "        choices = ['1', '2', '3']\n",
    "\n",
    "        X_copy['display_technology'] = np.select(conditions, choices, default='1')\n",
    "        X_copy['display_technology'] = pd.to_numeric(X_copy['display_technology'], errors='coerce')\n",
    "\n",
    "        return X_copy.copy()\n",
    "\n",
    "class KMeansClusterTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, kmeans_model, feature_names_at_imputer_stage=None):\n",
    "        self.kmeans_model = kmeans_model\n",
    "        self.feature_names_at_imputer_stage = feature_names_at_imputer_stage\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        if self.feature_names_at_imputer_stage is None:\n",
    "            raise ValueError(\"KMeansClusterTransformer requires 'feature_names_at_imputer_stage' to be set in its constructor.\")\n",
    "\n",
    "        if not isinstance(X, pd.DataFrame):\n",
    "            X_df_reconstructed = pd.DataFrame(X, columns=self.feature_names_at_imputer_stage)\n",
    "        else:\n",
    "            X_df_reconstructed = X.copy()\n",
    "\n",
    "        kmeans_expected_features = self.kmeans_model.feature_names_in_ if hasattr(self.kmeans_model, 'feature_names_in_') else self.feature_names_at_imputer_stage\n",
    "        for col in kmeans_expected_features:\n",
    "            if col not in X_df_reconstructed.columns:\n",
    "                X_df_reconstructed[col] = 0\n",
    "\n",
    "        X_cluster = X_df_reconstructed[kmeans_expected_features].copy()\n",
    "\n",
    "        X_df_reconstructed['Cluster'] = self.kmeans_model.predict(X_cluster)\n",
    "        return X_df_reconstructed.copy()\n",
    "\n",
    "\n",
    "try:\n",
    "    name_encoder = joblib.load('name_label_encoder.pkl')\n",
    "    kmeans_model = joblib.load('kmeans_model.pkl')\n",
    "    print(\"Đã tải thành công các encoder và KMeans model từ file .pkl.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Lỗi: Không tìm thấy một hoặc nhiều file encoder/KMeans .pkl.\")\n",
    "    print(\"Vui lòng đảm bảo các file này đã được tạo và lưu trong thư mục 'modeling/' trước khi chạy phần này.\")\n",
    "    raise\n",
    "\n",
    "final_dropper_cols_for_pipeline = [\n",
    "    'image', 'screen_size', 'battery',\n",
    "    'time', 'warranty', 'warranty_processed',\n",
    "    'color', 'has_nano_sim', 'price_old', 'day_remaining_warranty'\n",
    "]\n",
    "\n",
    "temp_pipeline_for_feature_names_pre_imputer_kmeans = Pipeline([\n",
    "    ('initial_dropper', Dropper(columns=['image'])),\n",
    "    ('datetime_features', DateTimeFeaturesTransformer()),\n",
    "    ('screen_resolution_transformer', ScreenResolutionTrasformer()),\n",
    "    ('condition_transformer', ConditionTransformer()),\n",
    "    ('brand_transformer', BrandTransformer()),\n",
    "    ('name_encoder', NameEncoder(encoder=name_encoder)),\n",
    "    ('gpu_transformer', GPUTransformer()),\n",
    "    ('bluetooth_transformer', BluetoothTransformer()),\n",
    "    ('price_new_transformer', PriceNewTransformer()),\n",
    "    ('cpu_transformer', CPUTransformer()),\n",
    "    ('operating_system_transformer', OperatingSystemTransformer()),\n",
    "    ('display_technology_transformer', DisplayTechnologyTransformer()),\n",
    "    ('final_dropper_for_cols', Dropper(columns=[col for col in final_dropper_cols_for_pipeline if col != 'image']))\n",
    "])\n",
    "\n",
    "temp_X_transformed_pre_imputer_kmeans = temp_pipeline_for_feature_names_pre_imputer_kmeans.fit_transform(X_original.copy())\n",
    "feature_names_at_imputer_stage = temp_X_transformed_pre_imputer_kmeans.columns.tolist()\n",
    "print(f\"Các đặc trưng trước imputer/KMeans: {feature_names_at_imputer_stage}\")\n",
    "\n",
    "prediction_pipeline = Pipeline([\n",
    "    ('initial_dropper', Dropper(columns=['image'])),\n",
    "    ('datetime_features', DateTimeFeaturesTransformer()),\n",
    "    ('screen_resolution_transformer', ScreenResolutionTrasformer()),\n",
    "    ('condition_transformer', ConditionTransformer()),\n",
    "    ('brand_transformer', BrandTransformer()),\n",
    "    ('name_encoder', NameEncoder(encoder=name_encoder)),\n",
    "    ('gpu_transformer', GPUTransformer()),\n",
    "    ('bluetooth_transformer', BluetoothTransformer()),\n",
    "    ('price_new_transformer', PriceNewTransformer()),\n",
    "    ('cpu_transformer', CPUTransformer()),\n",
    "    ('operating_system_transformer', OperatingSystemTransformer()),\n",
    "    ('display_technology_transformer', DisplayTechnologyTransformer()),\n",
    "    ('final_dropper', Dropper(columns=[col for col in final_dropper_cols_for_pipeline if col != 'image'])),\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('kmeans_cluster', KMeansClusterTransformer(kmeans_model=kmeans_model, feature_names_at_imputer_stage=feature_names_at_imputer_stage))\n",
    "])\n",
    "\n",
    "print(\"Đang fit pipeline dự đoán...\")\n",
    "fitted_prediction_pipeline = prediction_pipeline.fit(X_original.copy())\n",
    "print(\"Pipeline dự đoán đã được fit thành công.\")\n",
    "\n",
    "joblib.dump(fitted_prediction_pipeline, 'prediction_pipeline.pkl')\n",
    "print(\"prediction_pipeline.pkl đã được lưu thành công.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
